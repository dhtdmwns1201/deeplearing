{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeplearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnfqUCEr2Lvysj7bdFACw3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhtdmwns1201/deeplearing/blob/main/deeplearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtzsbkTvw_7D"
      },
      "source": [
        "#파이토치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCPRLK62soG-"
      },
      "source": [
        "import torch\r\n",
        "import numpy as np\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzgMT9n7suoa",
        "outputId": "bb93a4d5-0897-44fb-ac8d-f19d464120af"
      },
      "source": [
        "t = np.array([[[0,1,2,],\r\n",
        "                [4,5,6,]],\r\n",
        "                       \r\n",
        "            [[7.,8.,9.],\r\n",
        "             [10.,11.,12.]]])\r\n",
        "\r\n",
        "ft = torch.FloatTensor(t)\r\n",
        "print(ft.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksPiOwGSs-dr",
        "outputId": "5d398768-4b56-48d0-dc02-38e541e81b14"
      },
      "source": [
        "print(ft.view([-1, 3]))\r\n",
        "print(ft.view([-1, 3]).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.,  1.,  2.],\n",
            "        [ 4.,  5.,  6.],\n",
            "        [ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])\n",
            "torch.Size([4, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krvKbbtqtEeS",
        "outputId": "524bbc6b-6588-4fba-c375-a76b25a2775b"
      },
      "source": [
        "#3차원 공간으로 표현할 때는 (x,y,z) x = 행렬 개수 y = 행수 z = 열수\r\n",
        "#2차원일 때 세로는 dim = 0 가로는 dim = 1\r\n",
        "print(ft.view([-1,1,3]))\r\n",
        "print(ft.view([-1,1,3]).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.,  1.,  2.]],\n",
            "\n",
            "        [[ 4.,  5.,  6.]],\n",
            "\n",
            "        [[ 7.,  8.,  9.]],\n",
            "\n",
            "        [[10., 11., 12.]]])\n",
            "torch.Size([4, 1, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB9bl0MrtsmT"
      },
      "source": [
        " x = torch.FloatTensor([[1,2],[3,4]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSZSpr_s0EVS",
        "outputId": "e9073601-8615-49a2-9ae7-fc4f29823e7f"
      },
      "source": [
        "ft = torch.FloatTensor([[0],[1],[2]])\r\n",
        "print(ft) \r\n",
        "print(ft.size()) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [2.]])\n",
            "torch.Size([3, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nyXusx70QSw",
        "outputId": "dc71af36-9320-4a94-e7c4-25bd0da37081"
      },
      "source": [
        "#squeeze 를 이용하면 1dim 인 것에 대하여 그것을 지워 준다\r\n",
        "#최초(3,1) 행렬 이였는데 뒤에 1을 지워서 사이즈는 3 행렬 적인 개념으로 접근하면 (1,3)행렬을 만든다\r\n",
        "\r\n",
        "\r\n",
        "print(ft.squeeze(dim = 1))\r\n",
        "\r\n",
        "print(ft.squeeze().size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 1., 2.])\n",
            "torch.Size([3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7hO3DVO0ZIC",
        "outputId": "1f99b72e-0139-4426-ed62-e622f1925146"
      },
      "source": [
        "x = torch.FloatTensor([[1,2],[3,4]])\r\n",
        "y = torch.FloatTensor([[5,6],[7,8]])\r\n",
        "print(torch.cat([x,y],dim = 0))\r\n",
        "print(torch.cat([x,y],dim = 1))\r\n",
        "print(torch.cat([x,y],dim = 0).size())\r\n",
        "print(torch.cat([x,y],dim = 1).size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.],\n",
            "        [7., 8.]])\n",
            "tensor([[1., 2., 5., 6.],\n",
            "        [3., 4., 7., 8.]])\n",
            "torch.Size([4, 2])\n",
            "torch.Size([2, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4VLQGJh1iiJ",
        "outputId": "f764094d-49ac-4a28-9038-104565a3c4c0"
      },
      "source": [
        "x = torch.FloatTensor([[1,2],[3,4]])\r\n",
        "print(x.mul(2))#메모리에 선언하지 않음 \r\n",
        "print(x)\r\n",
        "print(x.mul_(2))\r\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n",
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0UN_I-A1_FC"
      },
      "source": [
        "#공부한 시간과 점수의 상관 관계\r\n",
        "#선형회귀 , 평균 제곱 오차, 경사 하강법\r\n",
        "#W 와 b 를 0으로 초기화 -> 항상 0출력\r\n",
        "#MSE "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9P1cHG65RUY"
      },
      "source": [
        "x_train = torch.FloatTensor([[1],[2],[3]])\r\n",
        "y_train = torch.FloatTensor([[1],[2],[3]])\r\n",
        "W = torch.zeros(1,requires_grad = True)\r\n",
        "#b = torch.zeros(1,requires_grad = True)\r\n",
        "hypothesis = x_train * W + b #예측값이 될것이다. \r\n",
        "cost = torch.mean((hypothesis - y_train)**2) #모델이 실제 데이터와 얼마나 다를까. -> cost를 최소화 하여야한다.\r\n",
        "optimizer = optim.SGD([W,b],lr = 0.01)\r\n",
        "optimizer.zero_grad()\r\n",
        "cost.backward()\r\n",
        "optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-VEaMHP5hA8"
      },
      "source": [
        "#데이터값\r\n",
        "x_train = torch.FloatTensor([[1],[2],[3]])\r\n",
        "y_train = torch.FloatTensor([[1],[2],[3]])\r\n",
        "#모델의 초기화 \r\n",
        "W = torch.zeros(1,requires_grad = True)\r\n",
        "#learning rate 설정\r\n",
        "lr = 0.1\r\n",
        "\r\n",
        "nb_epochs = 10\r\n",
        "for epoch in range(nb_epochs + 1):\r\n",
        "    #H(x) 계산\r\n",
        "    hypothesis = x_train * W\r\n",
        "    #cost gradient 계산\r\n",
        "    cost = torch.mean((hypothesis - y_train)**2)\r\n",
        "    gradient = torch.sum((W*x_train - y_train)*x_train)\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8QIafZU-z7R"
      },
      "source": [
        "#optimizer설정 \r\n",
        "optimzer = optim.SGD([w],lr = 0.15)\r\n",
        "#cost로 H(x) 개선\r\n",
        "optimizer.zero_grad() #기울기값 0으로 초기화 \r\n",
        "cost.backward() # 코스트 변수에서 기울기 값 계산\r\n",
        "optimizer.step() # 기울기 값 하강 gredient값을 이용하여 cost값을 줄인다. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws1Tl-8Q_8PG"
      },
      "source": [
        "#H(x) = Wx + b\r\n",
        "#x라는 vector 와 W라는 matrix 의 곱 b는 bias\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUNMAGQ2DeaB",
        "outputId": "70d1b402-546e-4b78-b951-075dc90a833b"
      },
      "source": [
        "x_train = torch.FloatTensor([[1],[2],[3]])\r\n",
        "y_train = torch.FloatTensor([[1],[2],[3]])\r\n",
        "W = torch.zeros(1) #프린트 시 [0,] 로 출력\r\n",
        "lr = 0.1 #학습 rate\r\n",
        "nb_epochs = 10 #총 학습 횟수\r\n",
        "for epoch in range(nb_epochs + 1):\r\n",
        "    hypothesis = x_train * W\r\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\r\n",
        "    gradient = torch.sum((W * x_train - y_train)*x_train)\r\n",
        "    print('Epch {:4d}/{} W :{:.3f} , Cost : {:.6f}'.format(epoch, nb_epochs,W.item(),cost.item()))\r\n",
        "    print(W)\r\n",
        "    W -= lr * gradient"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epch    0/10 W :0.000 , Cost : 4.666667\n",
            "tensor([0.])\n",
            "Epch    1/10 W :1.400 , Cost : 0.746666\n",
            "tensor([1.4000])\n",
            "Epch    2/10 W :0.840 , Cost : 0.119467\n",
            "tensor([0.8400])\n",
            "Epch    3/10 W :1.064 , Cost : 0.019115\n",
            "tensor([1.0640])\n",
            "Epch    4/10 W :0.974 , Cost : 0.003058\n",
            "tensor([0.9744])\n",
            "Epch    5/10 W :1.010 , Cost : 0.000489\n",
            "tensor([1.0102])\n",
            "Epch    6/10 W :0.996 , Cost : 0.000078\n",
            "tensor([0.9959])\n",
            "Epch    7/10 W :1.002 , Cost : 0.000013\n",
            "tensor([1.0016])\n",
            "Epch    8/10 W :0.999 , Cost : 0.000002\n",
            "tensor([0.9993])\n",
            "Epch    9/10 W :1.000 , Cost : 0.000000\n",
            "tensor([1.0003])\n",
            "Epch   10/10 W :1.000 , Cost : 0.000000\n",
            "tensor([0.9999])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rex2DW1DeX2",
        "outputId": "50d47270-e508-4f87-d804-09219f154a7a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ4jzblzFJ68"
      },
      "source": [
        "#너무 많은 데이터를 다룰 때는 minibatch gradient descent를 사용한다.\r\n",
        "from torch.utils.data import Dataset \r\n",
        "\r\n",
        "class CustomDataset(Dataset):\r\n",
        "    def __init__(self):\r\n",
        "        self.x_data = [[73,80,75],\r\n",
        "                       [93,88,93],\r\n",
        "                       [89,91,90],\r\n",
        "                       [96,98,100],\r\n",
        "                       [73,66,70]]\r\n",
        "        self.y_data = [[152],[185],[180],[196],[142]]\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.x_data) \r\n",
        "    def __getitem__(self,idx):\r\n",
        "        x = torch.FloatTensor(self.x_data[idx])\r\n",
        "        y = torch.FloatTensor(self.y_data[idx])\r\n",
        "        return x, y\r\n",
        "dataset = CustomDataset()\r\n",
        "\r\n",
        "from torch.untils.data import DataLoader \r\n",
        "\r\n",
        "dataloader = DataLoader(\r\n",
        "    dataset,batch_size = 2, suffle = True,\r\n",
        ")\r\n",
        "\r\n",
        "nb_epochs = 20 #총 학습 횟수\r\n",
        "for epoch in range(nb_epochs + 1):\r\n",
        "    for batch_idx, samples in enumerate(dataloader):\r\n",
        "        x_train , y_train = samples\r\n",
        "        prediction = moedel(x_train)\r\n",
        "\r\n",
        "        cost\r\n",
        "\r\n",
        "    hypothesis = x_train * W\r\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\r\n",
        "    gradient = torch.sum((W * x_train - y_train)*x_train)\r\n",
        "    print('Epch {:4d}/{} W :{:.3f} , Cost : {:.6f}'.format(epoch, nb_epochs,W.item(),cost.item()))\r\n",
        "    print(W)\r\n",
        "    W -= lr * gradient "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVGqI-FZf4j3"
      },
      "source": [
        "#Logistic Regression\r\n",
        "#가설 새로 : 개수 가로 : dimension\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn \r\n",
        "import torch.nn.functional as F \r\n",
        "import torch.optim as optim \r\n",
        "torch.manual_seed(1)\r\n",
        "\r\n",
        "x_data = [[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]]\r\n",
        "y_data = [[0],[0],[0],[1],[1],[1]]\r\n",
        "x_train = torch.FloatTensor(x_data)\r\n",
        "y_train = torch.FloatTensor(y_data)\r\n",
        "W = torch.zeros((2,1),requires_grad = True) \r\n",
        "b = torch.zeros(1,requires_grad = True)\r\n",
        "hypothesis = torch.sigmoid(x_train.matmul(W)+b)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZqRQO5W-tQY",
        "outputId": "d1b91505-e087-4deb-9e1f-11c1580d57b2"
      },
      "source": [
        "#이산적인 확률분포\r\n",
        "#softmax\r\n",
        "#ex) 가위바위보 예측?\r\n",
        "#P(주먹|가위) = ?? 확률분포를 정의할 수 있음\r\n",
        "#P(가위|가위) = ??\r\n",
        "#P(보|가위) = ??\r\n",
        "#이러한 확률분포를 근사시킨다. \r\n",
        "#max를 뽑는다면 가장 큰 것을 반환 \r\n",
        "#softmax를 활용한다면 비율에 따라 1이 되는 값을 나타내 준다. \r\n",
        "z = torch.FloatTensor([1,2,3])\r\n",
        "hypoehsis = F.softmax(z,dim = 0)\r\n",
        "print(hypoehsis) #합은 1이 된다. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0900, 0.2447, 0.6652])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoKP_oPrAR7D"
      },
      "source": [
        "#Cross Entropy를 최소화하는 것이 중요 \r\n",
        "#두개의 확률분포가 얼마나 비슷한지\r\n",
        "z = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKYvdCE9DI4U"
      },
      "source": [
        "#7강 모르는 건 찾아보기 시즌 1 찾아보기\r\n",
        "# 1 maximum likelihood estimation(최대가능도 추정)\r\n",
        "# 2 optimization via gradient descent \r\n",
        "# 3 overfitting and refrularization (과적합과 정규화)\r\n",
        "# 4 training and test dataset \r\n",
        "# 5 learnin rate (학습률)\r\n",
        "# 6 data preprocessin (데이터 전처리)\r\n",
        "# 1.MLE 왜하는지 : 확률에 대한 예측 n = 100 class1의 확률 = 27 이라고 가정(베르누이 실험)\r\n",
        "# 관찰값을 가장 잘 설명하는 확률분포 함수의 파라미터를 찾아내는 과정을 거친다.\r\n",
        "# 기울기를 구하여 접근 \r\n",
        "# 3. overfitting ex) o와x를 가르는 선을 찾고 싶다. 주어진 데이터에 대해 과도하게 맞춰서 선이 그어지는 것\r\n",
        "# overfitting을 최소화하는 것이 중요하다. test set을 이용하여 판단한다.\r\n",
        "# overfitting을 막는 방법 More data Less feautre regulariztion\r\n",
        "# regularization DNN(데이터 신경망)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsZ7CHgFLa4R"
      },
      "source": [
        "x_train = torch.FloatTensor([[1,2,1], #size(m,3)\r\n",
        "                             [1,3,2], \r\n",
        "                             [1,3,4],\r\n",
        "                             [1,5,5],\r\n",
        "                             [1,7,5],\r\n",
        "                             [1,2,5],\r\n",
        "                             [1,6,6],\r\n",
        "                             [1,7,7]\r\n",
        "                             ])\r\n",
        "y_train = torch.LongTensor([2,2,2,1,1,1,0,0]) #\r\n",
        "\r\n",
        "x_test = torch.FloatTensor([[2,1,1],[3,1,2],[3,3,4]])\r\n",
        "y_test = torch.LongTensor([2,2,2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5xXzsgYMNS7"
      },
      "source": [
        "class SoftmaxClassifierModel(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(). __init__()\r\n",
        "        self.linear = nn.Linear(3,3) #3개 벡터를 3개로 리턴해주는 함수\r\n",
        "    def forward(self,x):\r\n",
        "        return self.linear(x)\r\n",
        "model = SoftmaxClassifierModel()\r\n",
        "optimizer = optim.SGD(model.parameters(),lr = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAeLRNuWM6bg"
      },
      "source": [
        "def train(model,optimizer,x_train,y_train):\r\n",
        "    nb_epochs = 20 \r\n",
        "    for epoch in range(nb_epochs):\r\n",
        "        prediction = model(x_train)\r\n",
        "        cost = F.cross_entropy(prediction, y_train) #예측값과 y값이 얼마나 같은지\r\n",
        "        optimizer.zero_grad()\r\n",
        "        cost.backward()\r\n",
        "        optimizer.step()\r\n",
        "        print(epoch,cost.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGhGEzuNO1f9"
      },
      "source": [
        "#learning rate 가 발산하면 작게 cost가 줄어들지 않으면 크게 조정한다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmaq8KBEPt10"
      },
      "source": [
        "#데이터 전 처리 (정규 분포로 만들어 준다)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-LWvOlqZs5Q"
      },
      "source": [
        "#autograd back progation 을 이용해 파라미터를 업데이트 하는 방법은 autograd방식으로 쉽게 구현할 수 있다. 파라미터 업데이트 방법\r\n",
        "import torch\r\n",
        "\r\n",
        "if torch.cuda.is_avialable():\r\n",
        "    DEViCE =torch.device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v_hYCfGtiEh"
      },
      "source": [
        "파이썬 스터디 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5dQFk0CHmbI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgPh3YsrtkDh"
      },
      "source": [
        "import torch\r\n",
        "import torch.autograd #자동 미분함수 포함, 콘텍스트 메니저 \r\n",
        "import torch.nn  #신경망 구축을 위한 데이터 구조\r\n",
        "import torch.optim #SGD를 중심으로 한 파라미터 최적화 알고리즘\r\n",
        "import torch.utils.data #SGD 반복 연산을 실행할 때 사용하는 미니 배치용 유틸리티 함수 \r\n",
        "import torch.onnx #많이 사용하지는 않음 딥러닝간에 공유를 위한 포멧"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHav7_Ge1noS"
      },
      "source": [
        "#Tensor의 개념 이해하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkaRVJpj105c"
      },
      "source": [
        "a = 2 #스칼라\r\n",
        "b = [2,4] #벡터\r\n",
        "c = [[1,2],\r\n",
        "     [3,5]]\r\n",
        "d = [[[1,2],[2,4]],[[3,4],[5,6]],[[7,8],[9,10]]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8umV483u3J5",
        "outputId": "70144d1e-0059-4467-b0aa-203000055f59"
      },
      "source": [
        "2D Tensor \r\n",
        "|t| = (Batch size, dim)\r\n",
        "#아래의 그림과 같이 행렬에서 행의 크기가 batch size(row), 열의 크기가 dim(column)이라는 의미입니다.\r\n",
        "\r\n",
        "from sklearn.datasets import load_iris \r\n",
        "iris = load_iris()\r\n",
        "print (iris.data.shape)#row =150 col = 5(target 포함) \r\n",
        "iris['data'][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bssSIQm-3Kka",
        "outputId": "e4d4402b-07f3-4634-e17b-af10769e608b"
      },
      "source": [
        "iris.feature_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal length (cm)',\n",
              " 'sepal width (cm)',\n",
              " 'petal length (cm)',\n",
              " 'petal width (cm)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYumucLq3RQS",
        "outputId": "60be29fd-5fff-4ecc-943d-5b8823c38b11"
      },
      "source": [
        "iris.target_namesㅡ"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "7AAGIxsZ34zO",
        "outputId": "ddfbd8a6-76b5-4c97-c850-da9cbd85a038"
      },
      "source": [
        "#3D Tensor 의 예시\r\n",
        "\r\n",
        "from sklearn.datasets import load_digits\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "mnist = load_digits()\r\n",
        "print(mnist['images'].shape)\r\n",
        "plt.imshow(mnist['images'][100],cmap='gray')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1797, 8, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRZC20p335BN",
        "outputId": "ed2876cf-4a14-4f94-b96d-b627c6f7c165"
      },
      "source": [
        "import numpy as np\r\n",
        "t1 = np.array([0,1,2,3,4,5,6])\r\n",
        "print(t1.shape)\r\n",
        "(7,) - > (1,7) 이라는 뜻"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTAPXq4e5IBk"
      },
      "source": [
        "#2차원 데이터(흑백 사진이 대표적)\r\n",
        "t = np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.], [10., 11., 12.]])\r\n",
        "print(t) #넘파이는 딥러닝 할 때 잘 안쓴다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMhC9QZ5vEu3",
        "outputId": "1f326dcb-0b2e-4555-a5e6-0bea82a15d55"
      },
      "source": [
        "#pytorch 이용, gpu를 이용할 수 있게 한다. \r\n",
        "import torch\r\n",
        "t = torch.tensor([[1., 2., 3.],\r\n",
        "                  [4., 5., 6.],\r\n",
        "                  [7., 8., 9.],\r\n",
        "                  [10.,11.,12.]])\r\n",
        "print(t.dim())\r\n",
        "print(t.shape)\r\n",
        "print(t.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "torch.Size([4, 3])\n",
            "torch.Size([4, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4M4-T-zxdFh",
        "outputId": "3a89c0d6-e9fa-4ae4-ad4d-1d7488a9e663"
      },
      "source": [
        "print(t[:,1])\r\n",
        "print(t[:,1].size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 2.,  5.,  8., 11.])\n",
            "torch.Size([4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de8Y99YhxvgS",
        "outputId": "61764607-1246-45e8-b127-f862e0553f2b"
      },
      "source": [
        "print(t[:,:-1]) #맨마지막 꺼는 제거 하고 가져오기"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.,  2.],\n",
            "        [ 4.,  5.],\n",
            "        [ 7.,  8.],\n",
            "        [10., 11.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viVSMgN4yOV8",
        "outputId": "d2698550-4ada-46c7-af06-43623487ed2d"
      },
      "source": [
        "m1 = torch.tensor([[3., 3.]])\r\n",
        "m2 = torch.tensor([[2., 2.]])\r\n",
        "print(m1 + m2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5., 5.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhPK9WBlycXr",
        "outputId": "7941c87f-89de-40c7-d5a0-f016fc465b9e"
      },
      "source": [
        "#broad casting\r\n",
        "m1 = torch.tensor([[3,2]])\r\n",
        "m2 = torch.tensor([3])\r\n",
        "print(m1.dim())\r\n",
        "print(m1 + m2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "tensor([6, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVkeWwP76NTK",
        "outputId": "fa8cc998-ca9f-4816-bae0-cfe029a92d84"
      },
      "source": [
        "m1 = torch.FloatTensor([[1, 2]])\r\n",
        "m2 = torch.FloatTensor([[3], [4]])\r\n",
        "print(m1 + m2)\r\n",
        "print(m2.dim())\r\n",
        "print(m1.dim())\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4., 5.],\n",
            "        [5., 6.]])\n",
            "2\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J24bfoVD6xNi",
        "outputId": "5ac2a29f-d8bb-4517-ab6d-fc84b17c57ca"
      },
      "source": [
        "#floattensor란 텐서를 실수형으로 선언하는 것\r\n",
        "m1 = torch.FloatTensor([[1, 2], [3, 4]])\r\n",
        "m2 = torch.FloatTensor([[1], [2]])\r\n",
        "print('Shape of Matrix 1: ', m1.shape) \r\n",
        "print('Shape of Matrix 2: ', m2.shape) \r\n",
        "print(m1.matmul(m2)) #행렬곱"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Matrix 1:  torch.Size([2, 2])\n",
            "Shape of Matrix 2:  torch.Size([2, 1])\n",
            "tensor([[ 5.],\n",
            "        [11.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvv-zhYR7X9q",
        "outputId": "dac7ab50-c132-4edf-da28-aa7bdc180fc8"
      },
      "source": [
        "#토치에 내장 되어 있는 기능도 있음\r\n",
        "torch.matmul(m1,m2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.],\n",
              "        [11.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPO7W3Ru7flB",
        "outputId": "67e87b37-34ff-4ea0-be57-3bb0929511c1"
      },
      "source": [
        "#점곱\r\n",
        "print(m1.mul(m2))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [6., 8.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-tQsbAe7mJb",
        "outputId": "35bfc79a-7e4d-4ae7-be24-7463ee53eb5f"
      },
      "source": [
        "#평균\r\n",
        "t = torch.FloatTensor([[1, 2], [3, 4]])\r\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4SWXFG88Xgj",
        "outputId": "30c8fec3-681a-4d4a-b77c-26c606702be6"
      },
      "source": [
        "print(t.mean(dim = 0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RxuQT788ZoW",
        "outputId": "effc8660-7e67-48ab-d6cb-786cd272ff59"
      },
      "source": [
        "print(t.mean(dim = 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.5000, 3.5000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T03lG_FO8jZP",
        "outputId": "6003844a-7067-4862-97dc-d24816038c69"
      },
      "source": [
        "print(t.max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(4.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw7u8AVx8vqZ",
        "outputId": "5b5db79e-10a8-403a-8cda-df82f791bafe"
      },
      "source": [
        "print(t.max(dim = 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.return_types.max(\n",
            "values=tensor([2., 4.]),\n",
            "indices=tensor([1, 1]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPrkG0X_8zU3",
        "outputId": "88801ba4-a9ba-4530-afa2-e944ce02c7b3"
      },
      "source": [
        "print(t.sum(dim = 0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([4., 6.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRn0FhHkArab",
        "outputId": "32849161-636a-475f-9e98-de0ba817ba73"
      },
      "source": [
        "print(t.sum(dim = 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3., 7.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a09-JcPCAud8"
      },
      "source": [
        "#view 조작 하기 tensor의 크기를 변경해주는 역할 \r\n",
        "t = np.array([[[0, 1, 2],\r\n",
        "               [3, 4, 5]],\r\n",
        "              [[6, 7, 8],\r\n",
        "               [9, 10, 11]]])\r\n",
        "ft = torch.FloatTensor(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3w0QxQGA5wz",
        "outputId": "90ee4fb3-1c80-4b90-e7be-98752e694de1"
      },
      "source": [
        "print(ft.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQKYGNDABTg_",
        "outputId": "a3024486-4f5d-4315-89e0-12c40c5c34ea"
      },
      "source": [
        "print(ft.view([-1,3])) # 행수는 모르겠는데 열 수는 3개로 바꿔줘\r\n",
        "print(ft.view([-1,3]).size())\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.,  1.,  2.],\n",
            "        [ 3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.],\n",
            "        [ 9., 10., 11.]])\n",
            "torch.Size([4, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9X6FWI7BdXI",
        "outputId": "23928ec4-450c-4b4c-e423-57205847ae49"
      },
      "source": [
        "print(ft.view([2,6]))\r\n",
        "#컬럼이나 행을 결정하는 요소는 2x2x3 = 12 의 약수인 1,2,6,3,4,12 만 가능하다"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.,  9., 10., 11.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPrr_VjtBv3r",
        "outputId": "cfe9fe51-4d47-4b7f-b33b-e1de8f313c03"
      },
      "source": [
        "#squeeze 조작하기 1인차원을 제거한다\r\n",
        "ft = torch.FloatTensor([[0], [1], [2]])\r\n",
        "print(ft)\r\n",
        "print(ft.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [2.]])\n",
            "torch.Size([3, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz0-9lTlCMqb",
        "outputId": "d029733d-4bb2-4f41-ca2b-d4cdbedb4042"
      },
      "source": [
        "print(ft.squeeze())\r\n",
        "print(ft.squeeze().size()) #차원을 줄여준다"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 1., 2.])\n",
            "torch.Size([3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpMVoJJ5CQdW",
        "outputId": "e6b86d20-f317-4046-bcc3-b4705e9e7074"
      },
      "source": [
        "#unsqueeze 조작 하기 특정위치에 1인차원을 추가 한다. \r\n",
        "ft = torch.Tensor([0, 1, 2])\r\n",
        "print(ft.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcLOhS-4CgYc",
        "outputId": "ff8cee76-90f0-4bdc-c1f5-111c3970d882"
      },
      "source": [
        "print(ft.unsqueeze(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 1., 2.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVbOfwqgCm93",
        "outputId": "6f2892c3-07d2-4103-be16-a7ef42cd4e57"
      },
      "source": [
        "print(ft.view(1, -1))\r\n",
        "print(ft.view(1, -1).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 1., 2.]])\n",
            "torch.Size([1, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGD7oNbUC_85"
      },
      "source": [
        "#타입 캐스팅 중요!!!!\r\n",
        "#타임끼리만 연산 가능"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLi6gPObDmqU"
      },
      "source": [
        "#long tensor : 정수형 의미\r\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ2e7yD2DwLl",
        "outputId": "d52ec58b-f6cf-4b9e-a9c0-f62077f4410d"
      },
      "source": [
        "#True를 1로 \r\n",
        "bt = torch.ByteTensor([True, False, False, True])\r\n",
        "print(bt) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 0, 0, 1], dtype=torch.uint8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trfl8OUyDzdO",
        "outputId": "5d48148f-de94-43e2-d298-0f995cb683f1"
      },
      "source": [
        "#concatenate\r\n",
        "x = torch.FloatTensor([[1, 2], [3, 4]])\r\n",
        "y = torch.FloatTensor([[5, 6], [7, 8]])\r\n",
        "print(torch.cat([x,y],dim = 0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.],\n",
            "        [7., 8.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYhZntsbEJTs",
        "outputId": "35aeca87-9202-45c2-e808-8aa1b50395b9"
      },
      "source": [
        "print(torch.cat([x,y],dim = 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 5., 6.],\n",
            "        [3., 4., 7., 8.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9phTdsqGEXzD",
        "outputId": "9ef0a4dd-56b3-4c46-d690-33ae826ce1f8"
      },
      "source": [
        "#stacking 한번에 많은 것을 concatenate할 수 있다. \r\n",
        "x = torch.FloatTensor([1, 4])\r\n",
        "y = torch.FloatTensor([2, 5])\r\n",
        "z = torch.FloatTensor([3, 6])\r\n",
        "print(torch.stack([x,y,z],dim  = 1)) #열이 증가 하는 거니까 x,y,z 가 각각 열 행렬로 변경"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV-NW7F9HIHF",
        "outputId": "6f89ccf8-bab8-4d33-c3a1-e9d05b023f47"
      },
      "source": [
        "x = torch.FloatTensor([[0, 1, 2], [2, 1, 0]])\r\n",
        "print(x)\r\n",
        "print(torch.ones_like(x)) #같은 size를 1로 체우기 \r\n",
        "print(torch.zeros_like(x)) #같은 size를 0로 체우기"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 1., 2.],\n",
            "        [2., 1., 0.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tqZNTteEq9E",
        "outputId": "c6903b25-e85f-40e4-c1f9-4e070c18d406"
      },
      "source": [
        "#덮어쓰기 조작하기\r\n",
        "x = torch.FloatTensor([[1, 2], [3, 4]])\r\n",
        "print(x.mul(2))\r\n",
        "print(x)\r\n",
        "print(x.mul_(2))\r\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n",
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5x1SfJ-FVaO"
      },
      "source": [
        "#perceptron 인공 신경망 뉴런의 동작 방식을 본따 만든 것을 의미 \r\n",
        "#뉴런의 동작 방식은 입력 신호의 총 크기가 시놉시스를 전파하는 긴다면 다음으로 \r\n",
        "#and와 or 의 문제를 해결하기 위하여 만들어짐\r\n",
        "#xor 게이트는 같은 입력이 들어오면 0, 다른 입력이 들어오면 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro5abgF-AIHd"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "\r\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "torch.manual_seed(777)\r\n",
        "if device == 'cuda':\r\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-M_peiQS3US"
      },
      "source": [
        "#and or 연산의 이해 이런 식으로 w1 w2 b 를 찾는 과정을 \r\n",
        "def AND_gate(x1, x2):\r\n",
        "    w1=0.5\r\n",
        "    w2=0.5\r\n",
        "    b=-0.7\r\n",
        "    result = x1*w1 + x2*w2 + b\r\n",
        "    if result <= 0:\r\n",
        "        return 0\r\n",
        "    else:\r\n",
        "        return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TREV3uQ-S8eK",
        "outputId": "9bda478a-45ab-484a-d6f9-257af4998e94"
      },
      "source": [
        "AND_gate(1,1),AND_gate(1,0),AND_gate(0,0) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 0, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toCtoyhQ_WV2",
        "outputId": "18b07db2-434c-4ff3-c35b-d3488200d04d"
      },
      "source": [
        "#단층 perceptron 구현 xor 연산 기반\r\n",
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\r\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\r\n",
        "linear = nn.Linear(2, 1, bias=True)\r\n",
        "sigmoid = nn.Sigmoid()\r\n",
        "model = nn.Sequential(linear, sigmoid).to(device)\r\n",
        "# 비용 함수와 옵티마이저 정의\r\n",
        "criterion = torch.nn.BCELoss().to(device)\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr= 1)\r\n",
        "#10,001번의 에포크 수행. 0번 에포크부터 10,000번 에포크까지.\r\n",
        "for step in range(10001):\r\n",
        "    optimizer.zero_grad()\r\n",
        "    hypothesis = model(X)\r\n",
        "\r\n",
        "    # 비용 함수\r\n",
        "    cost = criterion(hypothesis, Y)\r\n",
        "    cost.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    if step % 100 == 0: # 100번째 에포크마다 비용 출력\r\n",
        "        print(step, cost.item())    \r\n",
        "\r\n",
        "#accuracy(정확도) = 0.5 밖에 안된다.                         "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.7273974418640137\n",
            "100 0.6931476593017578\n",
            "200 0.6931471824645996\n",
            "300 0.6931471824645996\n",
            "400 0.6931471824645996\n",
            "500 0.6931471824645996\n",
            "600 0.6931471824645996\n",
            "700 0.6931471824645996\n",
            "800 0.6931471824645996\n",
            "900 0.6931471824645996\n",
            "1000 0.6931471824645996\n",
            "1100 0.6931471824645996\n",
            "1200 0.6931471824645996\n",
            "1300 0.6931471824645996\n",
            "1400 0.6931471824645996\n",
            "1500 0.6931471824645996\n",
            "1600 0.6931471824645996\n",
            "1700 0.6931471824645996\n",
            "1800 0.6931471824645996\n",
            "1900 0.6931471824645996\n",
            "2000 0.6931471824645996\n",
            "2100 0.6931471824645996\n",
            "2200 0.6931471824645996\n",
            "2300 0.6931471824645996\n",
            "2400 0.6931471824645996\n",
            "2500 0.6931471824645996\n",
            "2600 0.6931471824645996\n",
            "2700 0.6931471824645996\n",
            "2800 0.6931471824645996\n",
            "2900 0.6931471824645996\n",
            "3000 0.6931471824645996\n",
            "3100 0.6931471824645996\n",
            "3200 0.6931471824645996\n",
            "3300 0.6931471824645996\n",
            "3400 0.6931471824645996\n",
            "3500 0.6931471824645996\n",
            "3600 0.6931471824645996\n",
            "3700 0.6931471824645996\n",
            "3800 0.6931471824645996\n",
            "3900 0.6931471824645996\n",
            "4000 0.6931471824645996\n",
            "4100 0.6931471824645996\n",
            "4200 0.6931471824645996\n",
            "4300 0.6931471824645996\n",
            "4400 0.6931471824645996\n",
            "4500 0.6931471824645996\n",
            "4600 0.6931471824645996\n",
            "4700 0.6931471824645996\n",
            "4800 0.6931471824645996\n",
            "4900 0.6931471824645996\n",
            "5000 0.6931471824645996\n",
            "5100 0.6931471824645996\n",
            "5200 0.6931471824645996\n",
            "5300 0.6931471824645996\n",
            "5400 0.6931471824645996\n",
            "5500 0.6931471824645996\n",
            "5600 0.6931471824645996\n",
            "5700 0.6931471824645996\n",
            "5800 0.6931471824645996\n",
            "5900 0.6931471824645996\n",
            "6000 0.6931471824645996\n",
            "6100 0.6931471824645996\n",
            "6200 0.6931471824645996\n",
            "6300 0.6931471824645996\n",
            "6400 0.6931471824645996\n",
            "6500 0.6931471824645996\n",
            "6600 0.6931471824645996\n",
            "6700 0.6931471824645996\n",
            "6800 0.6931471824645996\n",
            "6900 0.6931471824645996\n",
            "7000 0.6931471824645996\n",
            "7100 0.6931471824645996\n",
            "7200 0.6931471824645996\n",
            "7300 0.6931471824645996\n",
            "7400 0.6931471824645996\n",
            "7500 0.6931471824645996\n",
            "7600 0.6931471824645996\n",
            "7700 0.6931471824645996\n",
            "7800 0.6931471824645996\n",
            "7900 0.6931471824645996\n",
            "8000 0.6931471824645996\n",
            "8100 0.6931471824645996\n",
            "8200 0.6931471824645996\n",
            "8300 0.6931471824645996\n",
            "8400 0.6931471824645996\n",
            "8500 0.6931471824645996\n",
            "8600 0.6931471824645996\n",
            "8700 0.6931471824645996\n",
            "8800 0.6931471824645996\n",
            "8900 0.6931471824645996\n",
            "9000 0.6931471824645996\n",
            "9100 0.6931471824645996\n",
            "9200 0.6931471824645996\n",
            "9300 0.6931471824645996\n",
            "9400 0.6931471824645996\n",
            "9500 0.6931471824645996\n",
            "9600 0.6931471824645996\n",
            "9700 0.6931471824645996\n",
            "9800 0.6931471824645996\n",
            "9900 0.6931471824645996\n",
            "10000 0.6931471824645996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05wRlg6LD4DO"
      },
      "source": [
        "#Backpropagation\r\n",
        "#1. forward ->\r\n",
        "#2. backward -> 미분 값 계산 \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmedzM5jAnX4"
      },
      "source": [
        "#multylayer perceptron\r\n",
        "#여러 층을 쌓으면서 두줄로 나누는 것\r\n",
        "\r\n",
        "#Backpropagation\r\n",
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\r\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\r\n",
        "w1 = torch.Tensor(2,2).to(device)\r\n",
        "w1 = torch.Tensor(2).to(device)\r\n",
        "w1 = torch.Tensor(2,1).to(device)\r\n",
        "w1 = torch.Tensor(1).to(device)\r\n",
        "\r\n",
        "def sigmoid(x):\r\n",
        "    return 1.0 / (1.0 + torch.exp(-x))\r\n",
        "\r\n",
        "def simoid_prime(x):\r\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\r\n",
        "for step in range(10001): \r\n",
        "    l1 = torch.add(torch.matmu(X,w1),b1)\r\n",
        "    a1 = sigmoid(l1)\r\n",
        "    l2 = torch.add(torch.matmu(a1,w2),b2)\r\n",
        "    Y_pred = sigmoid(l2)\r\n",
        "\r\n",
        "    #바이너리 크로스 엔트로피\r\n",
        "    cost  = -torch.mean(Y*torch.log(Y_pred)+(1 - Y) * torch.log(1 - Y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDRajPT6JhUF",
        "outputId": "3d9212dc-7689-48a5-d58c-7400fb6f8e1e"
      },
      "source": [
        "#code : xor-nn \r\n",
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\r\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\r\n",
        "#nn Layer\r\n",
        "linear1 = nn.Linear(2,2,bias = True)\r\n",
        "linear2 = nn.Linear(2,1,bias = True)\r\n",
        "sigmoid = nn.Sigmoid()\r\n",
        "model = nn.Sequential(linear1,sigmoid,linear2,sigmoid).to(device)\r\n",
        "crierion = nn.BCELoss().to(device) #크로스 엔트로피 함수\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\r\n",
        "for step in range(10001):\r\n",
        "    optimizer.zero_grad()\r\n",
        "    hypothesis = model(X)\r\n",
        "    cost = criterion(hypothesis,Y)\r\n",
        "    cost.backward()\r\n",
        "    optimizer.step()\r\n",
        "    if step % 100 == 0:\r\n",
        "        print(step,cost.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.8614466190338135\n",
            "100 0.6930065751075745\n",
            "200 0.6925849318504333\n",
            "300 0.68949294090271\n",
            "400 0.6601967811584473\n",
            "500 0.5637606978416443\n",
            "600 0.4720391631126404\n",
            "700 0.3573341965675354\n",
            "800 0.11411609500646591\n",
            "900 0.05688456445932388\n",
            "1000 0.036910295486450195\n",
            "1100 0.027103299275040627\n",
            "1200 0.021335892379283905\n",
            "1300 0.017556410282850266\n",
            "1400 0.01489521935582161\n",
            "1500 0.012923291884362698\n",
            "1600 0.011405378580093384\n",
            "1700 0.010201795026659966\n",
            "1800 0.009224819019436836\n",
            "1900 0.008416290394961834\n",
            "2000 0.007736333180218935\n",
            "2100 0.007156721316277981\n",
            "2200 0.006656938698142767\n",
            "2300 0.006221630610525608\n",
            "2400 0.005839169025421143\n",
            "2500 0.005500460043549538\n",
            "2600 0.0051985206082463264\n",
            "2700 0.004927643574774265\n",
            "2800 0.004683340899646282\n",
            "2900 0.004461850970983505\n",
            "3000 0.004260209389030933\n",
            "3100 0.004075816832482815\n",
            "3200 0.0039065685123205185\n",
            "3300 0.003750707022845745\n",
            "3400 0.003606699872761965\n",
            "3500 0.0034732415806502104\n",
            "3600 0.0033491759095340967\n",
            "3700 0.0032336628064513206\n",
            "3800 0.0031257416121661663\n",
            "3900 0.0030247829854488373\n",
            "4000 0.002930037211626768\n",
            "4100 0.0028410092927515507\n",
            "4200 0.002757189329713583\n",
            "4300 0.002678173128515482\n",
            "4400 0.002603511093184352\n",
            "4500 0.002532843267545104\n",
            "4600 0.0024658855982124805\n",
            "4700 0.002402368001639843\n",
            "4800 0.0023420213256031275\n",
            "4900 0.002284590620547533\n",
            "5000 0.002229896606877446\n",
            "5100 0.0021777444053441286\n",
            "5200 0.0021279845386743546\n",
            "5300 0.0020804067607969046\n",
            "5400 0.0020348625257611275\n",
            "5500 0.0019913213327527046\n",
            "5600 0.0019495288142934442\n",
            "5700 0.0019094848539680243\n",
            "5800 0.0018710102885961533\n",
            "5900 0.0018341046525165439\n",
            "6000 0.0017985738813877106\n",
            "6100 0.0017643880564719439\n",
            "6200 0.0017314720898866653\n",
            "6300 0.0016997514758259058\n",
            "6400 0.0016691961791366339\n",
            "6500 0.0016396716237068176\n",
            "6600 0.001611163024790585\n",
            "6700 0.001583625446073711\n",
            "6800 0.001557028852403164\n",
            "6900 0.001531313406303525\n",
            "7000 0.0015064196195453405\n",
            "7100 0.0014823024393990636\n",
            "7200 0.0014589618658646941\n",
            "7300 0.0014362933579832315\n",
            "7400 0.0014143716543912888\n",
            "7500 0.0013931068824604154\n",
            "7600 0.0013724395539611578\n",
            "7700 0.0013523694360628724\n",
            "7800 0.001332881860435009\n",
            "7900 0.0013139763614162803\n",
            "8000 0.0012955338461324573\n",
            "8100 0.0012776884250342846\n",
            "8200 0.001260261284187436\n",
            "8300 0.0012432821094989777\n",
            "8400 0.0012267953716218472\n",
            "8500 0.0012106968788430095\n",
            "8600 0.0011950910557061434\n",
            "8700 0.0011797987390309572\n",
            "8800 0.0011649542720988393\n",
            "8900 0.0011504233116284013\n",
            "9000 0.0011362803634256124\n",
            "9100 0.0011224659392610192\n",
            "9200 0.0011089649051427841\n",
            "9300 0.0010957922786474228\n",
            "9400 0.001082962960936129\n",
            "9500 0.0010703874286264181\n",
            "9600 0.0010581252863630652\n",
            "9700 0.001046116929501295\n",
            "9800 0.0010344070615246892\n",
            "9900 0.0010229508625343442\n",
            "10000 0.0010116887278854847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1BJYYfHM9Ht"
      },
      "source": [
        "#Relu\r\n",
        "#시그모이드의 문제 \r\n",
        "#옵티마이저\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftXo13HDFlqx"
      },
      "source": [
        "#시그모이드는 엑티베이트 function 학습 알고리즘 -> vanishing gradient 알고리즘 \r\n",
        "#크로스 엔트로피는 loss를 구하는 알고리즘 \r\n",
        "#Relu f(x) = max(x,0)\r\n",
        "#optimizer 알고리즘 \r\n",
        "#torch.optim.SGD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "ORbwuK8pHGhN",
        "outputId": "83e04b50-fd28-4282-8205-14fd1e8ff26d"
      },
      "source": [
        "#mnist_softmax\r\n",
        "import torchvision.datasets as dsets\r\n",
        "mnist_train = dsets.MNIST(root = \"MNIST_data/\",train = True, transform = transform.ToTensor(),download = True)\r\n",
        "mnist_test = dsets.MNIST(root = \"MNIST_data/\",train = False, transform = transform.ToTensor(),download = True)\r\n",
        "data_loader = torch.utils.Dataloader(Dataloader = mnist_train, batch_size = batch_size, shuffle = True, drop_last = True)\r\n",
        "for X,Y in data_loader:\r\n",
        "    X = X.view(-1,28*28).to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0c675ddfa602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#mnistz_softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmnist_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"MNIST_data/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdownload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmnist_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"MNIST_data/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdownload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transform' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jik-6nN6Izes"
      },
      "source": [
        "#initalizing\r\n",
        "#pretraining\r\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvRMaraRfxnA"
      },
      "source": [
        "#overfitting\r\n",
        "#dropout 오버 피팅 문제 해결 방법\r\n",
        "#layer에 존재하는 노드들을 무작위로 껐다 켰다 하는 것 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPADK1OJyue7"
      },
      "source": [
        "#선형회귀 \r\n",
        "2.1 선형회귀\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdF7xJPO2QcE"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBA-R28b2TdM"
      },
      "source": [
        "#딥러닝의 기초 problem solve를 위해 만들어진 방법들 \r\n",
        "#ex)공장에서 공장에서의 불량률을 줄이고 싶어 \r\n",
        "#불량률에 대한 정의(수식을 이용한 표현)\r\n",
        "#불량률을 최소로 하는 기법 중의 하나가 딥러닝\r\n",
        "\r\n",
        "\r\n",
        "#데이터에 대한 이해 \r\n",
        "#가설의 수립 \r\n",
        "#손실 계산 \r\n",
        "#경사 하강법\r\n",
        "\r\n",
        "\r\n",
        "#OLS -> ordinary least square(선형 회귀) -> 머신 러닝의 일종 미분 값을 통해서 W와 b 를 구하는 가정 -> 다중공선성의 문제가 있음\r\n",
        "#mse 의 값을 최소화 시킨다. mean squared error\r\n",
        "#cost는 결국에 예측 값과 실제 값의 차이를 나타내기 위해 표현 하는 것을 의미한다\r\n",
        "#분류에서는 바이너리 크로스 엔트로피 사용"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LW10m-33N8F"
      },
      "source": [
        "2.1.1데이터에대한 이해\r\n",
        "\r\n",
        "     선형회귀를 이용한 공부한 시간과 점수에 대한 상관 관계\r\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9CYZs_C3Sb0",
        "outputId": "d5dbd414-82e2-48a0-cac7-12a69210bb36"
      },
      "source": [
        "#GD : 데이터 포인트를 모두 사용하는 것 \r\n",
        "#SGD : 데이터 포인트를 무작위로 (확률적으로) 데이터 포인트를 꺼내서 확인하는 것\r\n",
        "#Dataset : 뭐를\r\n",
        "#Dataloader : 어떻게\r\n",
        "#Model : 어디에  -> 무슨 데이터를 어떻게 가져와서 어디에 사용할 것인가.  \r\n",
        "#학습을 시킬지 정한다\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim \r\n",
        "\r\n",
        "torch.manual_seed(1)\r\n",
        "\r\n",
        "x_train = torch.FloatTensor([[1],[2],[3]])\r\n",
        "y_train = torch.FloatTensor([[2],[4],[6]])\r\n",
        "\r\n",
        "W = torch.zeros(1, requires_grad=True)#가중치 0인 것을 하나 만든다.학습을 통해 값이 계속 변경되는 값임을 명시 해준다.\r\n",
        "#print(W)\r\n",
        "b = torch.zeros(1, requires_grad=True)\r\n",
        "#hypothesis = x_train * W + b\r\n",
        "#print(hypothesis)\r\n",
        "#cost = torch.mean((hypothesis - y_train)**2)\r\n",
        "#print(cost)\r\n",
        "#경사 하강법 굉장히 중요\r\n",
        "optimizer = optim.SGD([W,b],lr = 0.01)  #학습 시킬 애를 SGD 에 넣어준다.\r\n",
        "\r\n",
        "nb_epochs = 4000\r\n",
        "\r\n",
        "for epoch in range(nb_epochs + 1):\r\n",
        "\r\n",
        "    hypothesis = x_train * W + b\r\n",
        "    cost = torch.mean((hypothesis - y_train)**2)\r\n",
        "\r\n",
        "    optimizer.zero_grad() #필요한 이유 : 파이토치는 gradient 값을 누적 시키는 성질이 있기 때문에\r\n",
        "    cost.backward() #자동 미분\r\n",
        "    optimizer.step() # W,b 를 업데이트\r\n",
        "\r\n",
        "    if epoch % 100 == 0:\r\n",
        "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\r\n",
        "            epoch, nb_epochs, W.item(), b.item(), cost.item()\r\n",
        "        ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/4000 W: 0.187, b: 0.080 Cost: 18.666666\n",
            "Epoch  100/4000 W: 1.746, b: 0.578 Cost: 0.048171\n",
            "Epoch  200/4000 W: 1.800, b: 0.454 Cost: 0.029767\n",
            "Epoch  300/4000 W: 1.843, b: 0.357 Cost: 0.018394\n",
            "Epoch  400/4000 W: 1.876, b: 0.281 Cost: 0.011366\n",
            "Epoch  500/4000 W: 1.903, b: 0.221 Cost: 0.007024\n",
            "Epoch  600/4000 W: 1.924, b: 0.174 Cost: 0.004340\n",
            "Epoch  700/4000 W: 1.940, b: 0.136 Cost: 0.002682\n",
            "Epoch  800/4000 W: 1.953, b: 0.107 Cost: 0.001657\n",
            "Epoch  900/4000 W: 1.963, b: 0.084 Cost: 0.001024\n",
            "Epoch 1000/4000 W: 1.971, b: 0.066 Cost: 0.000633\n",
            "Epoch 1100/4000 W: 1.977, b: 0.052 Cost: 0.000391\n",
            "Epoch 1200/4000 W: 1.982, b: 0.041 Cost: 0.000242\n",
            "Epoch 1300/4000 W: 1.986, b: 0.032 Cost: 0.000149\n",
            "Epoch 1400/4000 W: 1.989, b: 0.025 Cost: 0.000092\n",
            "Epoch 1500/4000 W: 1.991, b: 0.020 Cost: 0.000057\n",
            "Epoch 1600/4000 W: 1.993, b: 0.016 Cost: 0.000035\n",
            "Epoch 1700/4000 W: 1.995, b: 0.012 Cost: 0.000022\n",
            "Epoch 1800/4000 W: 1.996, b: 0.010 Cost: 0.000013\n",
            "Epoch 1900/4000 W: 1.997, b: 0.008 Cost: 0.000008\n",
            "Epoch 2000/4000 W: 1.997, b: 0.006 Cost: 0.000005\n",
            "Epoch 2100/4000 W: 1.998, b: 0.005 Cost: 0.000003\n",
            "Epoch 2200/4000 W: 1.998, b: 0.004 Cost: 0.000002\n",
            "Epoch 2300/4000 W: 1.999, b: 0.003 Cost: 0.000001\n",
            "Epoch 2400/4000 W: 1.999, b: 0.002 Cost: 0.000001\n",
            "Epoch 2500/4000 W: 1.999, b: 0.002 Cost: 0.000000\n",
            "Epoch 2600/4000 W: 1.999, b: 0.001 Cost: 0.000000\n",
            "Epoch 2700/4000 W: 2.000, b: 0.001 Cost: 0.000000\n",
            "Epoch 2800/4000 W: 2.000, b: 0.001 Cost: 0.000000\n",
            "Epoch 2900/4000 W: 2.000, b: 0.001 Cost: 0.000000\n",
            "Epoch 3000/4000 W: 2.000, b: 0.001 Cost: 0.000000\n",
            "Epoch 3100/4000 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 3200/4000 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 3300/4000 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 3400/4000 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 3500/4000 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 3600/4000 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 3700/4000 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 3800/4000 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 3900/4000 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 4000/4000 W: 2.000, b: 0.000 Cost: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srqtcqr8BgqM",
        "outputId": "3ff86121-39a0-4bf8-8750-d04ea3e51a25"
      },
      "source": [
        "y = W*torch.tensor(4)+b \r\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([8.0000], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqL-zBDjFndA",
        "outputId": "49ea138f-4abf-410d-80b3-42ecb9777c4f"
      },
      "source": [
        "#optimizer.zero_grad()가 필요한 이유\r\n",
        "#파이토치가 미분 값을 누적시키는 기능이 있기 때문에#optimizer.zero_grad() 으로 초기화 해준다 \r\n",
        "import torch\r\n",
        "w = torch.tensor(2.0, requires_grad=True)\r\n",
        "\r\n",
        "nb_epochs = 20\r\n",
        "for epoch in range(nb_epochs + 1):\r\n",
        "\r\n",
        "  z = 2*w\r\n",
        "  \r\n",
        "  z.backward()\r\n",
        "\r\n",
        "  print(f'수식을 w로 미분한 값 : {w.grad}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "수식을 w로 미분한 값 : 2.0\n",
            "수식을 w로 미분한 값 : 4.0\n",
            "수식을 w로 미분한 값 : 6.0\n",
            "수식을 w로 미분한 값 : 8.0\n",
            "수식을 w로 미분한 값 : 10.0\n",
            "수식을 w로 미분한 값 : 12.0\n",
            "수식을 w로 미분한 값 : 14.0\n",
            "수식을 w로 미분한 값 : 16.0\n",
            "수식을 w로 미분한 값 : 18.0\n",
            "수식을 w로 미분한 값 : 20.0\n",
            "수식을 w로 미분한 값 : 22.0\n",
            "수식을 w로 미분한 값 : 24.0\n",
            "수식을 w로 미분한 값 : 26.0\n",
            "수식을 w로 미분한 값 : 28.0\n",
            "수식을 w로 미분한 값 : 30.0\n",
            "수식을 w로 미분한 값 : 32.0\n",
            "수식을 w로 미분한 값 : 34.0\n",
            "수식을 w로 미분한 값 : 36.0\n",
            "수식을 w로 미분한 값 : 38.0\n",
            "수식을 w로 미분한 값 : 40.0\n",
            "수식을 w로 미분한 값 : 42.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSAvwoP6Hr3_",
        "outputId": "33799bc1-0dc8-4cd1-99ae-721bdd84bb29"
      },
      "source": [
        "#자동 미분\r\n",
        "w = torch.tensor(2.0, requires_grad=True)\r\n",
        "y = w**2\r\n",
        "z = 2*y + 5\r\n",
        "z.backward()\r\n",
        "print(f'수식을 w로 미분한 값 : {w.grad}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "수식을 w로 미분한 값 : 8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "405G_i91JSiA"
      },
      "source": [
        "다중 선형 회귀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37fC2-1WJNXA"
      },
      "source": [
        "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\r\n",
        "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\r\n",
        "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\r\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\r\n",
        "#x_train = torch.cat([x1_train,x2_train,x3_train],axis = 1) 보통이런 식으로 표현\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQrjwLugJrqn"
      },
      "source": [
        "#가중치 w 와 편의 b를 초기화\r\n",
        "w1 = torch.zeros(1,requires_grad = True)\r\n",
        "w2 = torch.zeros(1, requires_grad=True)\r\n",
        "w3 = torch.zeros(1, requires_grad=True)\r\n",
        "b = torch.zeros(1, requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WswZIxvqKCdI",
        "outputId": "6a5486fe-73cf-4968-d66a-c52d92a29cc7"
      },
      "source": [
        "#optimizer 설정\r\n",
        "optimizer = optim.SGD([w1, w2, w3, b], lr=1e-5)\r\n",
        "nb_epochs = 10000\r\n",
        "for epoch in range(nb_epochs + 1):\r\n",
        "\r\n",
        "    # H(x) 계산\r\n",
        "    hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\r\n",
        "\r\n",
        "    # cost 계산\r\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\r\n",
        "\r\n",
        "    # cost로 H(x) 개선\r\n",
        "    optimizer.zero_grad()\r\n",
        "    cost.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    # 100번마다 로그 출력\r\n",
        "    if epoch % 100 == 0:\r\n",
        "        print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\r\n",
        "            epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()\r\n",
        "        ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/10000 w1: 0.718 w2: 0.612 w3: 0.680 b: 0.009 Cost: 1.078964\n",
            "Epoch  100/10000 w1: 0.722 w2: 0.608 w3: 0.680 b: 0.009 Cost: 1.038180\n",
            "Epoch  200/10000 w1: 0.727 w2: 0.603 w3: 0.681 b: 0.010 Cost: 0.999513\n",
            "Epoch  300/10000 w1: 0.731 w2: 0.599 w3: 0.681 b: 0.010 Cost: 0.962859\n",
            "Epoch  400/10000 w1: 0.735 w2: 0.595 w3: 0.681 b: 0.010 Cost: 0.928092\n",
            "Epoch  500/10000 w1: 0.739 w2: 0.590 w3: 0.681 b: 0.010 Cost: 0.895123\n",
            "Epoch  600/10000 w1: 0.743 w2: 0.586 w3: 0.682 b: 0.010 Cost: 0.863870\n",
            "Epoch  700/10000 w1: 0.746 w2: 0.582 w3: 0.682 b: 0.010 Cost: 0.834221\n",
            "Epoch  800/10000 w1: 0.750 w2: 0.579 w3: 0.682 b: 0.010 Cost: 0.806112\n",
            "Epoch  900/10000 w1: 0.754 w2: 0.575 w3: 0.682 b: 0.010 Cost: 0.779432\n",
            "Epoch 1000/10000 w1: 0.757 w2: 0.571 w3: 0.682 b: 0.011 Cost: 0.754143\n",
            "Epoch 1100/10000 w1: 0.761 w2: 0.568 w3: 0.682 b: 0.011 Cost: 0.730145\n",
            "Epoch 1200/10000 w1: 0.764 w2: 0.564 w3: 0.682 b: 0.011 Cost: 0.707373\n",
            "Epoch 1300/10000 w1: 0.767 w2: 0.561 w3: 0.682 b: 0.011 Cost: 0.685790\n",
            "Epoch 1400/10000 w1: 0.770 w2: 0.558 w3: 0.682 b: 0.011 Cost: 0.665287\n",
            "Epoch 1500/10000 w1: 0.773 w2: 0.555 w3: 0.682 b: 0.011 Cost: 0.645847\n",
            "Epoch 1600/10000 w1: 0.776 w2: 0.552 w3: 0.682 b: 0.011 Cost: 0.627393\n",
            "Epoch 1700/10000 w1: 0.779 w2: 0.549 w3: 0.682 b: 0.012 Cost: 0.609883\n",
            "Epoch 1800/10000 w1: 0.782 w2: 0.546 w3: 0.682 b: 0.012 Cost: 0.593258\n",
            "Epoch 1900/10000 w1: 0.785 w2: 0.543 w3: 0.682 b: 0.012 Cost: 0.577480\n",
            "Epoch 2000/10000 w1: 0.788 w2: 0.540 w3: 0.682 b: 0.012 Cost: 0.562504\n",
            "Epoch 2100/10000 w1: 0.791 w2: 0.538 w3: 0.682 b: 0.012 Cost: 0.548294\n",
            "Epoch 2200/10000 w1: 0.793 w2: 0.535 w3: 0.682 b: 0.012 Cost: 0.534781\n",
            "Epoch 2300/10000 w1: 0.796 w2: 0.533 w3: 0.682 b: 0.012 Cost: 0.521965\n",
            "Epoch 2400/10000 w1: 0.798 w2: 0.530 w3: 0.682 b: 0.012 Cost: 0.509782\n",
            "Epoch 2500/10000 w1: 0.801 w2: 0.528 w3: 0.682 b: 0.013 Cost: 0.498215\n",
            "Epoch 2600/10000 w1: 0.803 w2: 0.526 w3: 0.681 b: 0.013 Cost: 0.487228\n",
            "Epoch 2700/10000 w1: 0.806 w2: 0.524 w3: 0.681 b: 0.013 Cost: 0.476795\n",
            "Epoch 2800/10000 w1: 0.808 w2: 0.521 w3: 0.681 b: 0.013 Cost: 0.466865\n",
            "Epoch 2900/10000 w1: 0.810 w2: 0.519 w3: 0.681 b: 0.013 Cost: 0.457435\n",
            "Epoch 3000/10000 w1: 0.812 w2: 0.517 w3: 0.681 b: 0.013 Cost: 0.448465\n",
            "Epoch 3100/10000 w1: 0.814 w2: 0.515 w3: 0.681 b: 0.013 Cost: 0.439954\n",
            "Epoch 3200/10000 w1: 0.817 w2: 0.514 w3: 0.680 b: 0.013 Cost: 0.431840\n",
            "Epoch 3300/10000 w1: 0.819 w2: 0.512 w3: 0.680 b: 0.013 Cost: 0.424140\n",
            "Epoch 3400/10000 w1: 0.821 w2: 0.510 w3: 0.680 b: 0.014 Cost: 0.416807\n",
            "Epoch 3500/10000 w1: 0.823 w2: 0.508 w3: 0.680 b: 0.014 Cost: 0.409832\n",
            "Epoch 3600/10000 w1: 0.825 w2: 0.507 w3: 0.679 b: 0.014 Cost: 0.403189\n",
            "Epoch 3700/10000 w1: 0.826 w2: 0.505 w3: 0.679 b: 0.014 Cost: 0.396877\n",
            "Epoch 3800/10000 w1: 0.828 w2: 0.503 w3: 0.679 b: 0.014 Cost: 0.390863\n",
            "Epoch 3900/10000 w1: 0.830 w2: 0.502 w3: 0.679 b: 0.014 Cost: 0.385131\n",
            "Epoch 4000/10000 w1: 0.832 w2: 0.500 w3: 0.678 b: 0.014 Cost: 0.379687\n",
            "Epoch 4100/10000 w1: 0.834 w2: 0.499 w3: 0.678 b: 0.014 Cost: 0.374489\n",
            "Epoch 4200/10000 w1: 0.835 w2: 0.497 w3: 0.678 b: 0.014 Cost: 0.369534\n",
            "Epoch 4300/10000 w1: 0.837 w2: 0.496 w3: 0.677 b: 0.015 Cost: 0.364814\n",
            "Epoch 4400/10000 w1: 0.839 w2: 0.495 w3: 0.677 b: 0.015 Cost: 0.360311\n",
            "Epoch 4500/10000 w1: 0.840 w2: 0.493 w3: 0.677 b: 0.015 Cost: 0.356024\n",
            "Epoch 4600/10000 w1: 0.842 w2: 0.492 w3: 0.676 b: 0.015 Cost: 0.351926\n",
            "Epoch 4700/10000 w1: 0.843 w2: 0.491 w3: 0.676 b: 0.015 Cost: 0.348020\n",
            "Epoch 4800/10000 w1: 0.845 w2: 0.490 w3: 0.676 b: 0.015 Cost: 0.344288\n",
            "Epoch 4900/10000 w1: 0.846 w2: 0.489 w3: 0.675 b: 0.015 Cost: 0.340734\n",
            "Epoch 5000/10000 w1: 0.848 w2: 0.488 w3: 0.675 b: 0.015 Cost: 0.337319\n",
            "Epoch 5100/10000 w1: 0.849 w2: 0.487 w3: 0.675 b: 0.016 Cost: 0.334072\n",
            "Epoch 5200/10000 w1: 0.851 w2: 0.486 w3: 0.674 b: 0.016 Cost: 0.330970\n",
            "Epoch 5300/10000 w1: 0.852 w2: 0.485 w3: 0.674 b: 0.016 Cost: 0.328004\n",
            "Epoch 5400/10000 w1: 0.853 w2: 0.484 w3: 0.674 b: 0.016 Cost: 0.325157\n",
            "Epoch 5500/10000 w1: 0.855 w2: 0.483 w3: 0.673 b: 0.016 Cost: 0.322430\n",
            "Epoch 5600/10000 w1: 0.856 w2: 0.482 w3: 0.673 b: 0.016 Cost: 0.319826\n",
            "Epoch 5700/10000 w1: 0.857 w2: 0.481 w3: 0.673 b: 0.016 Cost: 0.317333\n",
            "Epoch 5800/10000 w1: 0.858 w2: 0.480 w3: 0.672 b: 0.016 Cost: 0.314946\n",
            "Epoch 5900/10000 w1: 0.859 w2: 0.479 w3: 0.672 b: 0.016 Cost: 0.312656\n",
            "Epoch 6000/10000 w1: 0.861 w2: 0.478 w3: 0.671 b: 0.016 Cost: 0.310462\n",
            "Epoch 6100/10000 w1: 0.862 w2: 0.478 w3: 0.671 b: 0.017 Cost: 0.308345\n",
            "Epoch 6200/10000 w1: 0.863 w2: 0.477 w3: 0.671 b: 0.017 Cost: 0.306324\n",
            "Epoch 6300/10000 w1: 0.864 w2: 0.476 w3: 0.670 b: 0.017 Cost: 0.304373\n",
            "Epoch 6400/10000 w1: 0.865 w2: 0.476 w3: 0.670 b: 0.017 Cost: 0.302516\n",
            "Epoch 6500/10000 w1: 0.866 w2: 0.475 w3: 0.669 b: 0.017 Cost: 0.300714\n",
            "Epoch 6600/10000 w1: 0.867 w2: 0.474 w3: 0.669 b: 0.017 Cost: 0.298988\n",
            "Epoch 6700/10000 w1: 0.868 w2: 0.474 w3: 0.668 b: 0.017 Cost: 0.297328\n",
            "Epoch 6800/10000 w1: 0.869 w2: 0.473 w3: 0.668 b: 0.017 Cost: 0.295726\n",
            "Epoch 6900/10000 w1: 0.870 w2: 0.472 w3: 0.668 b: 0.017 Cost: 0.294178\n",
            "Epoch 7000/10000 w1: 0.871 w2: 0.472 w3: 0.667 b: 0.018 Cost: 0.292698\n",
            "Epoch 7100/10000 w1: 0.872 w2: 0.471 w3: 0.667 b: 0.018 Cost: 0.291263\n",
            "Epoch 7200/10000 w1: 0.873 w2: 0.471 w3: 0.666 b: 0.018 Cost: 0.289880\n",
            "Epoch 7300/10000 w1: 0.874 w2: 0.470 w3: 0.666 b: 0.018 Cost: 0.288539\n",
            "Epoch 7400/10000 w1: 0.875 w2: 0.470 w3: 0.665 b: 0.018 Cost: 0.287252\n",
            "Epoch 7500/10000 w1: 0.876 w2: 0.469 w3: 0.665 b: 0.018 Cost: 0.286006\n",
            "Epoch 7600/10000 w1: 0.877 w2: 0.469 w3: 0.665 b: 0.018 Cost: 0.284801\n",
            "Epoch 7700/10000 w1: 0.878 w2: 0.468 w3: 0.664 b: 0.018 Cost: 0.283628\n",
            "Epoch 7800/10000 w1: 0.879 w2: 0.468 w3: 0.664 b: 0.018 Cost: 0.282501\n",
            "Epoch 7900/10000 w1: 0.880 w2: 0.468 w3: 0.663 b: 0.018 Cost: 0.281403\n",
            "Epoch 8000/10000 w1: 0.880 w2: 0.467 w3: 0.663 b: 0.019 Cost: 0.280338\n",
            "Epoch 8100/10000 w1: 0.881 w2: 0.467 w3: 0.662 b: 0.019 Cost: 0.279307\n",
            "Epoch 8200/10000 w1: 0.882 w2: 0.467 w3: 0.662 b: 0.019 Cost: 0.278307\n",
            "Epoch 8300/10000 w1: 0.883 w2: 0.466 w3: 0.661 b: 0.019 Cost: 0.277333\n",
            "Epoch 8400/10000 w1: 0.884 w2: 0.466 w3: 0.661 b: 0.019 Cost: 0.276391\n",
            "Epoch 8500/10000 w1: 0.884 w2: 0.466 w3: 0.661 b: 0.019 Cost: 0.275468\n",
            "Epoch 8600/10000 w1: 0.885 w2: 0.465 w3: 0.660 b: 0.019 Cost: 0.274573\n",
            "Epoch 8700/10000 w1: 0.886 w2: 0.465 w3: 0.660 b: 0.019 Cost: 0.273705\n",
            "Epoch 8800/10000 w1: 0.887 w2: 0.465 w3: 0.659 b: 0.019 Cost: 0.272862\n",
            "Epoch 8900/10000 w1: 0.887 w2: 0.464 w3: 0.659 b: 0.019 Cost: 0.272026\n",
            "Epoch 9000/10000 w1: 0.888 w2: 0.464 w3: 0.658 b: 0.020 Cost: 0.271212\n",
            "Epoch 9100/10000 w1: 0.889 w2: 0.464 w3: 0.658 b: 0.020 Cost: 0.270428\n",
            "Epoch 9200/10000 w1: 0.890 w2: 0.464 w3: 0.657 b: 0.020 Cost: 0.269663\n",
            "Epoch 9300/10000 w1: 0.890 w2: 0.464 w3: 0.657 b: 0.020 Cost: 0.268907\n",
            "Epoch 9400/10000 w1: 0.891 w2: 0.463 w3: 0.656 b: 0.020 Cost: 0.268170\n",
            "Epoch 9500/10000 w1: 0.892 w2: 0.463 w3: 0.656 b: 0.020 Cost: 0.267451\n",
            "Epoch 9600/10000 w1: 0.892 w2: 0.463 w3: 0.655 b: 0.020 Cost: 0.266756\n",
            "Epoch 9700/10000 w1: 0.893 w2: 0.463 w3: 0.655 b: 0.020 Cost: 0.266057\n",
            "Epoch 9800/10000 w1: 0.894 w2: 0.463 w3: 0.654 b: 0.020 Cost: 0.265381\n",
            "Epoch 9900/10000 w1: 0.894 w2: 0.462 w3: 0.654 b: 0.020 Cost: 0.264718\n",
            "Epoch 10000/10000 w1: 0.895 w2: 0.462 w3: 0.654 b: 0.021 Cost: 0.264069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuuQDIrGKWSW"
      },
      "source": [
        "#위와 결과는 같지만 행렬을 한번에 선언하는 방법\r\n",
        "x_train  =  torch.FloatTensor([[73,  80,  75],  #x_train을 한번에 정의 \r\n",
        "                               [93,  88,  93], \r\n",
        "                               [89,  91,  90], \r\n",
        "                               [96,  98,  100],   \r\n",
        "                               [73,  66,  70]])  \r\n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\r\n",
        "W = torch.zeros((3, 1), requires_grad=True) # 5*3은 3*1과 matmul 해야하기 때문에\r\n",
        "b = torch.zeros(1, requires_grad=True)\r\n",
        "hypothesis = x_train.matmul(W) + b #matmul 사용"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yZ_h24hLbVW",
        "outputId": "39d57490-531b-434d-e868-6bc39bc74ad2"
      },
      "source": [
        "# 단순 선형 회귀 Linear 이용 Linear로 선언한 변수 안데 W,b가 포함 되어 있고 변수.parameter()을 이용하여 호출 가능하다. \r\n",
        "\r\n",
        "# 데이터\r\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\r\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\r\n",
        "\r\n",
        "# 모델을 선언 및 초기화. 단순 선형 회귀이므로 input_dim=1, output_dim=1.\r\n",
        "model = nn.Linear(1,1) #input_dim, output_dim = 1 \r\n",
        "print(list(model.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09lSgz-2MCu3",
        "outputId": "bc64adc5-876c-4e60-ffe5-df5360960e76"
      },
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\r\n",
        "\r\n",
        "# 전체 훈련 데이터에 대해 경사 하강법을 2,000회 반복\r\n",
        "nb_epochs = 2000\r\n",
        "for epoch in range(nb_epochs+1):\r\n",
        "\r\n",
        "    # H(x) 계산\r\n",
        "    prediction = model(x_train)\r\n",
        "\r\n",
        "    # cost 계산\r\n",
        "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\r\n",
        "\r\n",
        "    # cost로 H(x) 개선하는 부분\r\n",
        "    # gradient를 0으로 초기화\r\n",
        "    optimizer.zero_grad()\r\n",
        "    # 비용 함수를 미분하여 gradient 계산\r\n",
        "    cost.backward() # backward 연산\r\n",
        "    # W와 b를 업데이트\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    if epoch % 100 == 0:\r\n",
        "    # 100번마다 로그 출력\r\n",
        "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\r\n",
        "          epoch, nb_epochs, cost.item()\r\n",
        "      ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/2000 Cost: 13.103541\n",
            "Epoch  100/2000 Cost: 0.002791\n",
            "Epoch  200/2000 Cost: 0.001724\n",
            "Epoch  300/2000 Cost: 0.001066\n",
            "Epoch  400/2000 Cost: 0.000658\n",
            "Epoch  500/2000 Cost: 0.000407\n",
            "Epoch  600/2000 Cost: 0.000251\n",
            "Epoch  700/2000 Cost: 0.000155\n",
            "Epoch  800/2000 Cost: 0.000096\n",
            "Epoch  900/2000 Cost: 0.000059\n",
            "Epoch 1000/2000 Cost: 0.000037\n",
            "Epoch 1100/2000 Cost: 0.000023\n",
            "Epoch 1200/2000 Cost: 0.000014\n",
            "Epoch 1300/2000 Cost: 0.000009\n",
            "Epoch 1400/2000 Cost: 0.000005\n",
            "Epoch 1500/2000 Cost: 0.000003\n",
            "Epoch 1600/2000 Cost: 0.000002\n",
            "Epoch 1700/2000 Cost: 0.000001\n",
            "Epoch 1800/2000 Cost: 0.000001\n",
            "Epoch 1900/2000 Cost: 0.000000\n",
            "Epoch 2000/2000 Cost: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXXiWEMQM8Of",
        "outputId": "b605e6c3-f954-4495-fd4c-2daa747557c1"
      },
      "source": [
        "# 임의의 입력 4를 선언\r\n",
        "new_var =  torch.FloatTensor([[4.0]]) \r\n",
        "# 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장\r\n",
        "pred_y = model(new_var) # forward 연산\r\n",
        "# y = 2x 이므로 입력이 4라면 y가 8에 가까운 값이 나와야 제대로 학습이 된 것\r\n",
        "print(\"훈련 후 입력이 4일 때의 예측값 :\", pred_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 후 입력이 4일 때의 예측값 : tensor([[7.9989]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbb7oCBYNBo3",
        "outputId": "d0a70179-b01d-4eb1-fc77-826206b250b2"
      },
      "source": [
        "print(list(model.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[1.9994]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0014], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d1tlLk-NGLf"
      },
      "source": [
        "모델을 클래스로 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehXKAaMqOF5N"
      },
      "source": [
        "class LinearRegressionModel(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.linear = nn.Linear(1,1)\r\n",
        "\r\n",
        "    def forward(self,x):\r\n",
        "        return self.linear(x)\r\n",
        "model = LinearRegressionModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mABXQjV2On1X",
        "outputId": "d4c019c6-8fe7-4a0f-9362-4b9b59b5b8e7"
      },
      "source": [
        "#데이터 로드하기\r\n",
        "from torch.utils.data import TensorDataset # 텐서데이터셋\r\n",
        "from torch.utils.data import DataLoader # 데이터로더\r\n",
        "x_train  =  torch.FloatTensor([[73,  80,  75], \r\n",
        "                               [93,  88,  93], \r\n",
        "                               [89,  91,  90], \r\n",
        "                               [96,  98,  100],   \r\n",
        "                               [73,  66,  70]])  \r\n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\r\n",
        "\r\n",
        "dataset = TensorDataset(x_train, y_train)\r\n",
        "\r\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True) \r\n",
        "\r\n",
        "model = nn.Linear(3,1) \r\n",
        "\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\r\n",
        "nb_epochs = 20\r\n",
        "for epoch in range(nb_epochs + 1):\r\n",
        "  for batch_idx, samples in enumerate(dataloader):# enumerate : index 랑 아이템을 같이 리턴\r\n",
        "    x_train, y_train = samples\r\n",
        "    # H(x) 계산\r\n",
        "    prediction = model(x_train)\r\n",
        "\r\n",
        "    # cost 계산\r\n",
        "    cost = F.mse_loss(prediction, y_train)\r\n",
        "\r\n",
        "    # cost로 H(x) 계산\r\n",
        "    optimizer.zero_grad()\r\n",
        "    cost.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\r\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader),\r\n",
        "        cost.item()\r\n",
        "        ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/20 Batch 1/3 Cost: 67799.437500\n",
            "Epoch    0/20 Batch 2/3 Cost: 17139.009766\n",
            "Epoch    0/20 Batch 3/3 Cost: 8567.740234\n",
            "Epoch    1/20 Batch 1/3 Cost: 1624.912231\n",
            "Epoch    1/20 Batch 2/3 Cost: 617.507019\n",
            "Epoch    1/20 Batch 3/3 Cost: 154.058182\n",
            "Epoch    2/20 Batch 1/3 Cost: 39.125324\n",
            "Epoch    2/20 Batch 2/3 Cost: 20.664429\n",
            "Epoch    2/20 Batch 3/3 Cost: 26.171398\n",
            "Epoch    3/20 Batch 1/3 Cost: 5.714457\n",
            "Epoch    3/20 Batch 2/3 Cost: 5.922220\n",
            "Epoch    3/20 Batch 3/3 Cost: 2.598936\n",
            "Epoch    4/20 Batch 1/3 Cost: 4.784308\n",
            "Epoch    4/20 Batch 2/3 Cost: 7.743512\n",
            "Epoch    4/20 Batch 3/3 Cost: 1.987293\n",
            "Epoch    5/20 Batch 1/3 Cost: 6.287208\n",
            "Epoch    5/20 Batch 2/3 Cost: 6.177036\n",
            "Epoch    5/20 Batch 3/3 Cost: 2.176183\n",
            "Epoch    6/20 Batch 1/3 Cost: 6.899502\n",
            "Epoch    6/20 Batch 2/3 Cost: 3.185356\n",
            "Epoch    6/20 Batch 3/3 Cost: 10.895258\n",
            "Epoch    7/20 Batch 1/3 Cost: 5.568087\n",
            "Epoch    7/20 Batch 2/3 Cost: 3.566025\n",
            "Epoch    7/20 Batch 3/3 Cost: 8.012279\n",
            "Epoch    8/20 Batch 1/3 Cost: 8.157141\n",
            "Epoch    8/20 Batch 2/3 Cost: 1.121485\n",
            "Epoch    8/20 Batch 3/3 Cost: 10.328746\n",
            "Epoch    9/20 Batch 1/3 Cost: 6.765400\n",
            "Epoch    9/20 Batch 2/3 Cost: 9.919025\n",
            "Epoch    9/20 Batch 3/3 Cost: 5.346527\n",
            "Epoch   10/20 Batch 1/3 Cost: 3.050418\n",
            "Epoch   10/20 Batch 2/3 Cost: 5.569296\n",
            "Epoch   10/20 Batch 3/3 Cost: 10.792151\n",
            "Epoch   11/20 Batch 1/3 Cost: 5.965455\n",
            "Epoch   11/20 Batch 2/3 Cost: 8.718893\n",
            "Epoch   11/20 Batch 3/3 Cost: 10.370374\n",
            "Epoch   12/20 Batch 1/3 Cost: 9.058472\n",
            "Epoch   12/20 Batch 2/3 Cost: 7.998278\n",
            "Epoch   12/20 Batch 3/3 Cost: 1.219330\n",
            "Epoch   13/20 Batch 1/3 Cost: 8.407311\n",
            "Epoch   13/20 Batch 2/3 Cost: 0.789239\n",
            "Epoch   13/20 Batch 3/3 Cost: 10.745684\n",
            "Epoch   14/20 Batch 1/3 Cost: 3.557388\n",
            "Epoch   14/20 Batch 2/3 Cost: 7.542785\n",
            "Epoch   14/20 Batch 3/3 Cost: 3.593933\n",
            "Epoch   15/20 Batch 1/3 Cost: 10.147013\n",
            "Epoch   15/20 Batch 2/3 Cost: 7.273390\n",
            "Epoch   15/20 Batch 3/3 Cost: 0.994027\n",
            "Epoch   16/20 Batch 1/3 Cost: 7.149696\n",
            "Epoch   16/20 Batch 2/3 Cost: 5.626602\n",
            "Epoch   16/20 Batch 3/3 Cost: 1.847154\n",
            "Epoch   17/20 Batch 1/3 Cost: 6.818563\n",
            "Epoch   17/20 Batch 2/3 Cost: 3.922839\n",
            "Epoch   17/20 Batch 3/3 Cost: 6.043753\n",
            "Epoch   18/20 Batch 1/3 Cost: 1.436124\n",
            "Epoch   18/20 Batch 2/3 Cost: 8.497011\n",
            "Epoch   18/20 Batch 3/3 Cost: 8.217440\n",
            "Epoch   19/20 Batch 1/3 Cost: 7.430203\n",
            "Epoch   19/20 Batch 2/3 Cost: 4.180572\n",
            "Epoch   19/20 Batch 3/3 Cost: 9.305497\n",
            "Epoch   20/20 Batch 1/3 Cost: 2.952992\n",
            "Epoch   20/20 Batch 2/3 Cost: 13.076653\n",
            "Epoch   20/20 Batch 3/3 Cost: 2.716893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaDoZN72RQxL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "4d00b85d-04e6-4484-f0af-5b9e091ef095"
      },
      "source": [
        "#Mnist 이용하여 Multi Layer Perception(MLP) 설계하기\r\n",
        "#MLP 설계 순서\r\n",
        "#모듈 임포트 \r\n",
        "#장비(cuda)\r\n",
        "#mnist 다운로드 \r\n",
        "#데이터 확인 \r\n",
        "#모델 설계 \r\n",
        "#optimizer 설정 \r\n",
        "#함수 정의 \r\n",
        "\r\n",
        "#1 모듈 임포트 \r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt #함수 실행결과 산출물에 대한 수치를 시각화 해주는 함수\r\n",
        "import torch\r\n",
        "import torch.nn as nn #신경망 함수 집합 \r\n",
        "import torch.nn.functional as F  #위의 신경망 함수 중에서도 자주 사용하는것을 F로 지정 \r\n",
        "from torchvision import transforms, datasets #비전 연구에 이용하는것 \r\n",
        "\r\n",
        "#장비 확인 \r\n",
        "if torch.cuda.is_available():\r\n",
        "    DEVICE = torch.device('cuda')\r\n",
        "else:\r\n",
        "    DEVICE = torch.device('cpu')\r\n",
        "print('DEVICE : ', DEVICE)\r\n",
        "\r\n",
        "BATCH_SIZE = 32 #모델 학습에 필요한 데이터 개수의 단위 \r\n",
        "EPOCHS = 10\r\n",
        "\r\n",
        "#MNIST 데이터 다운 로드(TRAIN SET, TEST SET 으로 분리)\r\n",
        "train_dataset = datasets.MNIST(root = \"../data/MNIST\",\r\n",
        "                               train = True,\r\n",
        "                               download = True,\r\n",
        "                               transform = transforms.ToTensor())\r\n",
        "test_dataset = datasets.MNIST(root = \"../data/MNIST\",\r\n",
        "                               train = False,\r\n",
        "                               transform = transforms.ToTensor())\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, #다운로드 한 데이터 셋을 미니배치 단위로 분리해서 저장\r\n",
        "                                            batch_size = BATCH_SIZE,\r\n",
        "                                            shuffle = True)\r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\r\n",
        "                                            batch_size = BATCH_SIZE,\r\n",
        "                                            shuffle = False)\r\n",
        "#데이터 확인\r\n",
        "for (X_train, Y_train) in train_loader:\r\n",
        "    print('X_train_size :',X_train.size(),'type :',X_train.type())\r\n",
        "    print('Y_train_size :',Y_train.size(),'type :',Y_train.type())\r\n",
        "    break\r\n",
        "\r\n",
        "#X_train_size : torch.Size([32, 1, 28, 28]) type : torch.FloatTensor 32개의 이미지 데이터가 1개의 미니 배치를 구성 하고 있고 가로 28개 새로 28개의 픽셀 - > 흑백 \r\n",
        "#Y_train_size : torch.Size([32]) type : torch.LongTensor\r\n",
        "#데이터 확인\r\n",
        "pltsize = 1 \r\n",
        "plt.figure(figsize = (10 * pltsize, pltsize))\r\n",
        "for i in range(10):\r\n",
        "    plt.subplot(1,10,i+1)\r\n",
        "    plt.axis('off')\r\n",
        "    plt.imshow(X_train[i,:,:,:].numpy().reshape(28,28),cmap = \"gray_r\")\r\n",
        "\r\n",
        "    plt.title('class:'+str(Y_train[i].item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEVICE :  cpu\n",
            "X_train_size : torch.Size([32, 1, 28, 28]) type : torch.FloatTensor\n",
            "Y_train_size : torch.Size([32]) type : torch.LongTensor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_7lzRMzQQe-",
        "outputId": "6f24cc55-c39c-4609-bff0-ec6d1487ae2d"
      },
      "source": [
        "#모델 설계 하기\r\n",
        "class Net(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Net,self).__init__()\r\n",
        "        self.fc1 = nn.Linear(28*28 , 512)\r\n",
        "        self.fc2 = nn.Linear(512 , 256)\r\n",
        "        self.fc3 = nn.Linear(256 , 10)\r\n",
        "    def faward(self,x):\r\n",
        "        x = x.view(-1,28,28)\r\n",
        "        x = self.fc1(x)\r\n",
        "        x = F.sigmoid(x)\r\n",
        "        x = self.fc2(x)\r\n",
        "        x = F.sigmoid(x)\r\n",
        "        x = self.fc3(x)\r\n",
        "        x = F.log_softmax(x, dim = 1)\r\n",
        "        return x\r\n",
        "\r\n",
        "#Optimizer, Objective Function 설정하기\r\n",
        "model = Net().to(DEVICE)\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "print(model)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr7i0CkgZYus"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}